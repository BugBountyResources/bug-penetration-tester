Chapter 10. Formatting Your Report

Having a granular idea of the individual content, scenarios, and format of a great report example can help you shape your pentesting practice. As you continue to learn, refine your skills, and generally become a better researcher, you can adopt new tools, strategies, and other methods that are consistent with the end goal of creating that platonic perfect report, the one that will be instantly rewarded at the highest appropriate severity level.

The following topics will be covered in this chapter:

    Reproducing the bug – how your submission is vetted
    Critical information – what your report needs
    Maximizing your reward – the features that pay
    Example submission reports – where to look


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Reproducing the Bug – How Your Submission Is Vetted
    Reproducción del error: cómo se examina su envío

Without the internal security team being able to validate your findings by recreating your PoC, it's hard to get a reward.

The easiest way to ensure that your bug is reproducible is to, from the very beginning, practice reproducing it yourself.

Written up series of reproducible directions is easy if you
stress the right things . You should be careful to:

1-Use clearly numbered steps.

2-Note any in-app side effects, even if they're functional issues and not directly exploitable (for example, User info modal opens
    and closes immediately) because they might clue in the responding developer to an issue you're not aware of, and tell them they're on the right track.

    3-Include fine distinctions (clicking the submit button versus highlighting the submit button and hitting return) to provide as much useful context as possible, without going overboard. A good question is: are you rewording vague descriptions to be as specific as possible (good), or are you typing a stream-of-consciousness jargon salad, throwing every piece of information or data point at the wall to see what sticks (bad)?


    4-Beyond the descriptive quality of your reproducibility walkthrough itself, it's also important to include (useful) context about your environment that might go deeper than the Methodology section. For example, in Methodology, you might say I navigated to X page and filled the Y input with Z value, before using such-and-such tool. Some extra, useful context would be your browser type, version, and any applicable extensions or configurations that distinguish it. Unnecessary context might be that you also have a game installed on your system that's completely removed from any of your testing findings.

    5-Know your audience. This advice overlaps and extends our discussion of making the correct distinctions and adding the right technical detail. When you contact an internal security team, who responds will depend on the organization. At a small startup, you might get a developer (or even technical founder) to respond to your report. At a larger, more enterprise company, there will be dedicated security engineers and maybe even a proper Network Operations Center (NOC), which is essentially the nerve center of any network/data center. This means that, while you can't depend on your submission being read by a security expert, eventually, your report will get passed to the person tasked with writing the patch, and it should have the technical detail for them to start debugging. This means that if there's a descriptive error stack trace, for example—although it won't get you a reward—you can make the contributing developer's life easier by including it.

example:

    1- Navigate to an individual thread view (https://www.somesite.com/the/location/of/the/vulnerable/thread.html) and click the Add Comment button. Including a specific URL location is key—even if you have already added that data to another part of the report. Being specific about the action you're taking in the UI (click the Add Comment button) sounds unnecessarily detailed over something like submit the form, but is still useful.

    2- In the input textarea modal that opens, enter the following malicious XSS snippet. Then, click the Submit button:

<svg/onload=alert(document.location.origin)>

Make sure to describe the UX at every point where you're changing application state. Referencing the direct frontend components that are a part of the attack surface you're testing will help the developers/engineers involved recreate the entire input chain, from frontend submission to (in this case, failed) backend validation.

    3- When the code submits successfully, you should be redirected back to the page of the thread where you were adding the comment. You should see that the script has executed, alert()-ing the URL location of the vulnerability.


Using document.location.origin allows us to prove to the team receiving our submission that the XSS is being executed on an active, non-sandboxed production instance, where it can affect live user data. We've also included a screenshot showing the actual execution of our vulnerability. It's great if you want to include a screenshot for each individual step, which can reveal markup artifacts that might be of interest to the app's developers, but the essential state to capture is the execution of the vulnerability PoC.


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Critical Information – What Your Report Needs

Although report information will vary based on what the vulnerability is (you might stumble upon encoded-but-decodable sensitive material, which would mean that you wouldn't have any Payload information to submit), there is a common set of fields you will always need:

    The location (URL) of the vulnerability
    The vulnerability type
    When it was found
    How it was found (automated/manual, tool)
    How to reproduce it
    How the bug can be exploited


We've had examples throughout this book of each of these fields, but there are two in particular that deserve greater mention. The
location URL is clear, as well as the type, time, method, and all direct information, but ensuring the bug in the report is
reproducible and that there's a compelling attack scenario detailing the horrific things it has done, leaving the bug un-
patched will be critical to both ensuring your bug gets rewarded and with the highest possible payout.

    Beyond the essential information, a comprehensive reproducibility path, and a compelling attack scenario, there is also some extra data you can include, some that's vulnerability-specific and some that's optional-but-illuminating.

f you're reporting on a vulnerability that features a payload, that's important. Including links to reference pages from OWASP, NIST, and other respected security organizations can also be an effective way of clearly communicating the nature and type of vulnerability – directly referencing an OWASP page for a certain XSS type,

for example :

    (https://www.owasp.org/index.php/Testing_for_Reflected_Cross_site_scripting_(OTG-INPVAL-001))
I
mmediately shows that you're familiar with the nature of the bug and understand its fundamental principles. If you're writing
about an attack scenario enabled by a Known Component Vulnerability, it's vital that you include its CVE ID and a link to its vulnerability page.

Your attack might make accessible flat files available, or they might be included as evidence of the vulnerability
    (for example, maybe you've discovered an old sample config file on the server with real credential values and you want to send a copy as part of your submission).
While you might be able to send the files as corroborating evidence to your report, consider that you should only expect to
send relatively safe files, such as .txt, .json, .xml, or other common data types.
No security team wants to risk the accidental execution of a .exe or other potential malware. If possible, only include the relevant portion of the total file.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Maximizing Your Award – The Features That Pay

If you'd like to get a sense of the payout you can expect for a certain bug, it's useful to look at both the individual page of
the bounty you're participating in and a vulnerability rating system created by Bugcrowd called the :
    Vulnerability Rating Taxonomy (VRT).
        The VRT (https://bugcrowd.com/vulnerability-rating-taxonomy)
    is an attempt to systematically assess a vulnerability's severity in a way that provides a common frame of reference for researchers, developers, and managers alike.

    The VRT is also compatible with another attempt at providing a common threat metric, the

    Common Vulnerability Scoring System (CVSS)—VRT can be used to calculate CVSS.
    Understanding the VRT can help you direct your efforts to bugs that will give you the most value for your time.

Writing a bounty that will get you the proper restitution for the bug's severity requires that you can get the security team
vetting your submission to reproduce your attack, but also—just as, if not more importantly—you need to write a compelling attack scenario.
    To write a compelling attack scenario, you need a few things:

    Specificity:
        Your attack scenario should have specific varieties of bugs and exploits in mind and, if at all possible, mention a specific piece that's opposed to its type (username and not auth data—unless that is the best description for the multiple pieces of information you've gathered).
        Always name an application's version, include any metadata you have access to, and so on.

    Realistic severity:
        Your vulnerability might not crash every hosting region, or cripple the company's infrastructure,
        but it will impose a serious set of risks for employees, customers, investors, and anyone else caught in the crossfire of an exploitation.

        You should be able to define an attack scenario that's realistic (it can't take crazy resources, or unlimited time),
        but should lead to unacceptable data loss, data theft, performance degradation, or a loss in basic functionality, as these are all clear crises.


    Proper terminology:
        Using the correct jargon (technical terms, acronyms, applicable metaphors)
        assures the security team vetting your submission that your attack scenario is credible because you are credible.
        You don't want to bungle a submission reward because you describe what might be a legitimate find in awkward, confusing, or misleading ways.
        Being able to leverage common terms such as :
            Remote Code Execution (RCE)and PoC is essential.

    Documentation:
        This is the report! (Right?)
        The other sections are related considerations, but the more you can attach about the scenario itself, the better.
        This could mean a screenshot, file, or artifact created as a side effect of the discovery, or even data along-the-way-but-still-short of an active exploitation path, proving,
        for example,
            that you can print out sensitive cookie information without actually exfiltrating or abusing the information.

Keeping these principles in mind,
let's look at an example of a poorly written report and contrast it with a stronger attempt, assuming that we're submitting a report on the same vulnerability we discussed earlier—persistent XSS, discovered in the comments section of a popular online forum.

    Weak:
        Using the vulnerability, someone could attack the site's user community by putting a malicious script in a popular thread.

    Stronger:
        An attacker could exploit the persistent XSS vulnerability by inserting a malicious JavaScript snippet into a comment on a popular thread that could steal admin account cookies by sending them to a listening server.



Notice that the second, stronger attack scenario is still succinct—keeping the scenario detailed but terse is important.

It uses specific over-generic terms (JavaScript, versus script, comment on a popular thread versus in a popular thread, admin account cookies, and so on)
and it enumerates a possible risk
    (steal admin account cookies)
that's more than just vague hand-waving about a malicious script, representing a specific, damaging scenario.

This scenario is also within the bounds of the bug's severity: XSS won't bring down the world's financial system like some
rampaging sci-fi super-worm, but it can do great harm to individual users.

    Example Submission Reports – Where to Look

    But one of the best ways to learn to do anything is to model your practice after other successful researchers and to see their expertise in action rather than accept it as received wisdom.
        !Read enough successful reports (that have earned a reward) and you begin to see the themes connecting them, and the practices underpinning those researchers' successful careers.
Here are a few resources for seeing those examples—battle-tested reports that have won their authors acclaim and awards.


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Hackerone Hacktivity
    Hackerone's Hacktivity section
        (https://hackerone.com/hacktivity)
    is an archive of vulnerability report submissions organized in a Reddit-style voting system, where the community can upvote particularly interesting reports to feature them on the section's front page

    Since reports are only made public after the bounty program manager has consented, you can see that many of them are greyed-out.

    But those that are visible provide a window into not only the security culture of the participating companies, but the everyday pentesting regimen of successful researchers.


Vulnerability Lab Archive
    We first discussed Vulnerability Lab, like Hackerone, in the context of good bug bounty researcher communities.

    In addition to being a great source for discovering new bounty programs, Vulnerability Lab also maintainsan          archive    (https://www.vulnerability-lab.com/)
    of all the bug reports submitted on its platform (whose program owners also agree to publicly disclosing the vulnerability)

    One of the most valuable elements of the Vulnerability Lab archive is that each report is organized by type—whether it's a web application, mobile app, or general vendor vulnerability—making it easy to drill down into the reports that are most relevant to your practice.


GitHub
    GitHub's bug bounty page
    (https://bounty.github.com/)
    not only features the leaderboard for all the security researchers who have participated in its program, displaying
    the username, profile picture, and Twitter handle of the contributor,
    it also gives you some basic information about the bugs they've discovered—their category, subtype, and a high-level
    explanatory paragraph about where the vulnerability was discovered and its impacted services

    As valuable as these reports are, though, they don't feature the technical detail (code snippets, screenshots, and relevant file attachments) that the previous two collections of vulnerability reports typically show.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Summary
This chapter discusses the finer points of writing a vulnerability report submission that we might have glossed over
in our attack chapters,
explaining the critical information that should be included in every report, optional information, the importance of including detailed steps to reproduce the bug,
how to write a good attack scenario (with examples),
where to find real-life production bug report submissions, and more.
Building on the sample submission reports we've created throughout our vulnerability walkthrough chapters with more high-
level discussion of what makes a report worth a reward,
this chapter should give you everything you need moving forward to write quality reports that win you the maximum payout for the bugs you've discovered.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Further Reading

You can find out more about some of the topics we have discussed in this chapter at:

    GitHub Bug Bounty FAQs: https://bounty.github.com/index.html#faqs.

    Bug submission methodology: https://www.bugcrowd.com/writing-successful-bug-submissions-bug-bounty-hunter-methodology/
